{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.signal import convolve2d as conv2\n",
    "from numpy import histogram as hist\n",
    "from scipy import ndimage\n",
    "sys.path.append('..')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will first familiarise yourself with basic image filtering routines. In the second part, you will develop a simple image querying system that accepts a query image as input and then finds a set of similar images in the database. To compare images, you will implement some simple histogram-based distance functions and evaluate their performance in combination with different image representations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Image Filtering (10 points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.1** Implement a method `gauss` in `utils/image_filtering.py` that computes the values of a 1-D Gaussian for a given variance $\\sigma^2$. The method should also return a vector of integers on which we define the Gaussian filter: as common practice, return integers in the interval $[-3\\sigma,3\\sigma]$.\n",
    "  \n",
    "\\begin{equation}\n",
    "  G=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp(-\\frac{x^2}{2\\sigma^2}).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.image_filtering import gauss\n",
    "\n",
    "### The following code is used for evaluation.\n",
    "\n",
    "sigma = 4.0\n",
    "[gx, x] = gauss(sigma)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, gx, '.-')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.2** Implement a 2D Gaussian filter `gaussianfilter` in `utils/image_filtering.py`. The function should take an image as an input and return the result of the convolution of this image a with 2D Gaussian kernel of given variance $\\sigma^2$. See **Figure 1** for an illustration of Gaussian filtering. You can take advantage of the `convolve2d` function from the `scipy` library if you don't want to implement convolution yourself.\n",
    "\n",
    "*Hint: use the fact that the 2D Gaussian filter is separable to speed up computations.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 1: Left: Original image. Right: Image after applying a Gaussian filter with $\\sigma = 4.0$.**\n",
    "\n",
    "<!-- <img src=\"../../data/exercise-1/not_smooth.png\" width=\"300\" align=left />\n",
    "<img src=\"../../data/exercise-1/smooth.png\" width=\"300\" align=left /> -->\n",
    "![](../../data/exercise-1/not_smooth.png)\n",
    "![](../../data/exercise-1/smooth.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.image_filtering import gaussianfilter, rgb2gray\n",
    "\n",
    "### The following code is used for evaluation.\n",
    "\n",
    "def run_one_img_q1_2(image_path):\n",
    "    img = rgb2gray(np.array(Image.open(image_path)))\n",
    "    smooth_img = gaussianfilter(img, sigma)\n",
    "\n",
    "    plt.figure()\n",
    "    ax1 = plt.subplot(1,2,1)\n",
    "    ax2 = plt.subplot(1,2,2)\n",
    "    plt.sca(ax1)\n",
    "    plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.sca(ax2)\n",
    "    plt.imshow(smooth_img, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.show()\n",
    "    \n",
    "run_one_img_q1_2('../../data/exercise-1/night.png')\n",
    "run_one_img_q1_2('../../data/exercise-1/kand.png')\n",
    "run_one_img_q1_2('../../data/exercise-1/graf.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.3** Implement a function `gaussdx` in `utils/image_filtering.py` for creating a Gaussian derivative filter in 1D according to the following equation:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d}{dx}G = \\frac{d}{dx}\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp(-\\frac{x^2}{2\\sigma^2})\\\\\n",
    "    = -\\frac{1}{\\sqrt{2\\pi}\\sigma^3}x \\exp(-\\frac{x^2}{2\\sigma^2})\n",
    "\\end{equation}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect of applying a filter can be studied by observing its\n",
    "so-called $\\textit{impulse response}$. For this, create a test image\n",
    "in which only the central pixel has a non-zero value:\n",
    "\n",
    "```\n",
    "  imgImp = np.zeros((27,27))\n",
    "  imgImp[13,13] = 1.0\n",
    "```\n",
    "\n",
    "Now, create the following 1D filter kernels $G$ and $D$.\n",
    "\n",
    "```\n",
    "  sigma = 7.0\n",
    "  G = gauss(sigma)\n",
    "  D = gaussdx(sigma)\n",
    "```\n",
    "\n",
    "What happens when you apply the following filter combinations?\n",
    "- first $G$,  then $G^T$;\n",
    "- first $G$,  then $D^T$;\n",
    "- first $D$,  then $G^T$;\n",
    "- first $G^T$, then $D$;\n",
    "- first $D^T$, then $G$,\n",
    "\n",
    "where $G^T$ refers to the transpose of vector $G$.\n",
    "Visualize the results and summarize in the cell below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.image_filtering import gaussdx\n",
    "\n",
    "### The following code is used for evaluation.\n",
    "\n",
    "img = np.zeros([27,27])\n",
    "img[13, 13] = 1.0\n",
    "plt.figure(), plt.imshow(img, cmap='gray')\n",
    "\n",
    "sigma = 7.0\n",
    "[G, x] = gauss(sigma)\n",
    "[D, x] = gaussdx(sigma)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, G, 'b.-')\n",
    "plt.plot(x, D, 'r-')\n",
    "plt.legend( ('gauss', 'gaussdx'))\n",
    "plt.show()\n",
    "\n",
    "G = G.reshape(1, G.size)\n",
    "D = D.reshape(1, D.size)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(conv2(conv2(img, G, 'same'), G.T, 'same') , cmap='gray')\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(conv2(conv2(img, G, 'same'), D.T, 'same') , cmap='gray')\n",
    "plt.subplot(2,3,3)\n",
    "plt.imshow(conv2(conv2(img, D.T, 'same'), G, 'same') , cmap='gray')\n",
    "plt.subplot(2,3,4)\n",
    "plt.imshow(conv2(conv2(img, D, 'same'), D.T, 'same') , cmap='gray')\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(conv2(conv2(img, D, 'same'), G.T, 'same') , cmap='gray')\n",
    "plt.subplot(2,3,6)\n",
    "plt.imshow(conv2(conv2(img, G.T, 'same'), D, 'same') , cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.4** Use the functions `gauss` and `gaussdx` in order to implement a function `gaussderiv` in `utils/image_filtering.py` that returns the 2D Gaussian derivatives of an input image in x and y direction. Try the function on the three test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.image_filtering import gaussderiv\n",
    "\n",
    "### The following code is used for evaluation.\n",
    "\n",
    "def run_one_img_q1_4(image_path):\n",
    "    img_c = np.array(Image.open(image_path)).astype('double')\n",
    "    img = rgb2gray(img_c)\n",
    "    [imgDx, imgDy] = gaussderiv(img, 7.0)\n",
    "\n",
    "    plt.figure()\n",
    "    ax1 = plt.subplot(1,3,1)\n",
    "    ax2 = plt.subplot(1,3,2)\n",
    "    ax3 = plt.subplot(1,3,3)\n",
    "    plt.sca(ax1)\n",
    "    plt.imshow(imgDx, cmap='gray')\n",
    "    plt.sca(ax2)\n",
    "    plt.imshow(imgDy, cmap='gray')\n",
    "    plt.sca(ax3)\n",
    "    imgmag = np.sqrt(imgDx**2 + imgDy**2)\n",
    "    plt.imshow(imgmag, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "run_one_img_q1_4('../../data/exercise-1/night.png')\n",
    "run_one_img_q1_4('../../data/exercise-1/kand.png')\n",
    "run_one_img_q1_4('../../data/exercise-1/graf.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Image Representations and Histogram Distances (10 points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.1** Implement a function `normalized_histogram` in `utils/image_histograms.py`, which takes a gray-value image as input and returns a normalized histogram of pixel intensities. Compare your implementation with the built-in Python function `numpy.histogram`. Your histograms and the histograms computed with Python should be approximately the same, except for the overall scale, which will be different since `numpy.histogram` does not normalize its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.image_histograms import normalized_histogram\n",
    "\n",
    "### The following code is used for evaluation.\n",
    "\n",
    "img_color = np.array(Image.open('../../data/exercise-1/model/obj100__0.png'))\n",
    "img_gray = rgb2gray(img_color.astype('double'))\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(img_color)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "num_bins_gray = 40\n",
    "hist_gray1, bin_gray1 = hist(img_gray.reshape(img_gray.size), num_bins_gray,(0,255))\n",
    "plt.bar((bin_gray1[0:-1] + bin_gray1[1:])/2, hist_gray1)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "hist_gray2, bin_gray2 = normalized_histogram(img_gray, num_bins_gray)\n",
    "plt.bar((bin_gray2[0:-1] + bin_gray2[1:])/2, hist_gray2)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.2** Implement other histogram types discussed during the tutorial (refer to the introduction slides). Your implementation should extend the code provided in the functions `rgb_hist`, `rg_hist`, and `dxdy_hist` in `utils/image_histograms.py`. Make sure that you are using the correct range of pixel values. For “RGB” the pixel intensities are in \\[0, 255\\], for “rg” the values are normalized to be in \\[0, 1\\]. For the derivatives histograms the values depend on the σ2 of the Gaussian filter; with σ = 7.0 you can assume that the values are in the range \\[−32, 32\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.image_histograms import rgb_hist, rg_hist, dxdy_hist\n",
    "\n",
    "### The following code is used for evaluation.\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img_color)\n",
    "\n",
    "num_bins_color = 5\n",
    "plt.subplot(1,2,2)\n",
    "hist_rgb1 = rgb_hist(img_color.astype('double'), num_bins_color)\n",
    "plt.bar(np.array(range(1,hist_rgb1.size+1)),hist_rgb1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img_color)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "num_bins_rg = 5\n",
    "hist_rg = rg_hist(img_color.astype('double'), num_bins_rg)\n",
    "plt.bar(np.array(range(1,hist_rg.size+1)),hist_rg)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img_color)\n",
    "\n",
    "num_bins_dxdy = 10\n",
    "plt.subplot(1,2,2)\n",
    "hist_dxdy = dxdy_hist(img_gray.astype('double'), num_bins_dxdy)\n",
    "plt.bar(np.array(range(1,hist_dxdy.size+1)),hist_dxdy)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.3** Implement the histogram distance functions discussed during the tutorial (refer to the introduction slides), by filling the missing code in the functions `dist_l2`, `dist_intersect`, and `dist_chi2` in `utils/image_histograms.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.image_histograms import get_dist_by_name, get_hist_by_name, is_grayvalue_hist\n",
    "\n",
    "### The following code is used for evaluation.\n",
    "\n",
    "image_files1 = ['../../data/exercise-1/model/obj1__0.png']\n",
    "image_files2 = ['../../data/exercise-1/model/obj91__0.png', '../../data/exercise-1/model/obj94__0.png']\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,3,1); plt.imshow(np.array(Image.open(image_files1[0])), vmin=0, vmax=255); plt.title(image_files1[0].split('/')[-1].split('.')[0])\n",
    "plt.subplot(1,3,2); plt.imshow(np.array(Image.open(image_files2[0])), vmin=0, vmax=255); plt.title(image_files2[0].split('/')[-1].split('.')[0])\n",
    "plt.subplot(1,3,3); plt.imshow(np.array(Image.open(image_files2[1])), vmin=0, vmax=255); plt.title(image_files2[1].split('/')[-1].split('.')[0])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('distance functions:')\n",
    "distance_types = ['l2', 'intersect', 'chi2']\n",
    "print(distance_types)\n",
    "print('\\n')\n",
    "\n",
    "print('histogram types:')\n",
    "hist_types = ['grayvalue', 'rgb', 'rg', 'dxdy']\n",
    "print(hist_types)\n",
    "print('\\n')\n",
    "\n",
    "num_bins_color = 30\n",
    "num_bins_gray = 90\n",
    "\n",
    "for imgidx1 in range(len(image_files1)):\n",
    "    img1_color = np.array(Image.open(image_files1[imgidx1]))\n",
    "    img1_gray = rgb2gray(img1_color.astype('double'))\n",
    "    img1_color = img1_color.astype('double')\n",
    "\n",
    "    for imgidx2 in range(len(image_files2)):\n",
    "        img2_color = np.array(Image.open(image_files2[imgidx2]))\n",
    "        img2_gray = rgb2gray(img2_color.astype('double'))\n",
    "        img2_color = img2_color.astype('double')\n",
    "\n",
    "        D = np.zeros( (len(distance_types), len(hist_types)) )\n",
    "\n",
    "        for didx in range(len(distance_types)):\n",
    "\n",
    "            for hidx in range(len(hist_types)):\n",
    "\n",
    "                if is_grayvalue_hist(hist_types[hidx]):\n",
    "                  hist1 = get_hist_by_name(img1_gray, num_bins_gray, hist_types[hidx])\n",
    "                  hist2 = get_hist_by_name(img2_gray, num_bins_gray, hist_types[hidx])\n",
    "\n",
    "                  if len(hist1) == 2 and len(hist1[0]) > 1:\n",
    "                      hist1 = hist1[0]\n",
    "                  if len(hist2) == 2 and len(hist2[0]) > 1:\n",
    "                      hist2 = hist2[0]\n",
    "\n",
    "                  D[didx,hidx] = get_dist_by_name(hist1, hist2, distance_types[didx])\n",
    "                \n",
    "                else:\n",
    "                  \n",
    "                  hist1 = get_hist_by_name(img1_color, num_bins_color, hist_types[hidx])\n",
    "                  hist2 = get_hist_by_name(img2_color, num_bins_color, hist_types[hidx])\n",
    "\n",
    "                  if len(hist1) == 2 and len(hist1[0]) > 1:\n",
    "                      hist1 = hist1[0]\n",
    "                  if len(hist2) == 2 and len(hist2[0]) > 1:\n",
    "                      hist2 = hist2[0]\n",
    "\n",
    "                  D[didx, hidx] = get_dist_by_name(hist1, hist2, distance_types[didx])\n",
    "\n",
    "        print('compare image \"%s\" to \"%s\":'% (image_files1[imgidx1].split('/')[-1].split('.')[0], image_files2[imgidx2].split('/')[-1].split('.')[0]))\n",
    "        print(D)\n",
    "        print('\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Object Identification (10 points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.1** Having implemented different distance functions and image histograms, we can now test how suitable they are for retrieving images in a query-by-example scenario. Implement a function `find_best_match` in `utils/object_identification.py`, which takes a list of model images and a list of query images and for each query image returns the index of the closest model image. The function should take string parameters, which identify the distance function, the histogram function, and the number of histogram bins. See the comments at the beginning of `find_best_match` for more details. Aside from the indices of the best matching images, your implementation should also return a matrix that contains the distances between all pairs of model and query images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.object_identification import find_best_match\n",
    "\n",
    "### The following code is used for evaluation.\n",
    "\n",
    "with open('../../data/exercise-1/model.txt') as fp:\n",
    "    model_images = fp.readlines()\n",
    "model_images = [x.strip() for x in model_images] \n",
    "\n",
    "with open('../../data/exercise-1/query.txt') as fp:\n",
    "    query_images = fp.readlines()\n",
    "query_images = [x.strip() for x in query_images] \n",
    "\n",
    "eval_dist_type = 'intersect'\n",
    "eval_hist_type = 'rg'\n",
    "eval_num_bins = 30\n",
    "\n",
    "[best_match, D] = find_best_match(model_images, query_images, eval_dist_type, eval_hist_type, eval_num_bins)\n",
    "\n",
    "print(best_match)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.2** Implement a function `show_neighbors` in `utils/object_identification.py` that takes a list of model images and a list of query images and for each query image visualizes several model images which are the closest to the query image according to the specified distance metric. Use the function `find_best_match` in your implementation. See **Figure 2** for an example output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2: A query image and the model images with color histograms similar to the query image.**\n",
    "\n",
    "<!-- <img src=\"../../data/exercise-1/fig2.png\" width=\"600\" align=left /> -->\n",
    "![](../../data/exercise-1/fig2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.object_identification import show_neighbors\n",
    "\n",
    "### The following code is used for evaluation.\n",
    "\n",
    "query_images_vis = [query_images[i] for i in np.array([0,4,9])]\n",
    "show_neighbors(model_images, query_images_vis, eval_dist_type, eval_hist_type, eval_num_bins)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Performance Evaluation (10 points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.1** Sometimes instead of returning the best match for a query image, we would like to return all the model images with a distance to the query image below a certain threshold. It is, for example, the\n",
    "case when there are multiple images of the query object among the model images. In order to assess\n",
    "  the system performance in such scenario, we will use two quality measures: precision and\n",
    "  recall. Denoting the threshold on the distance between the images by $\\tau$ and using the following\n",
    "  notation:\n",
    "\n",
    "\n",
    "TP (True Positive) = number of correct matches among the images with distance smaller than $\\tau$,\n",
    "<br>\n",
    "FP (False Positive) = number of incorrect matches among the images with distance smaller than $\\tau$,\n",
    "<br>\n",
    "TN (True Negative) = number of incorrect matches among the images with distance larger than $\\tau$,\n",
    "<br>\n",
    "FN (False Negative) = number of correct matches among the images with distance larger than $\\tau$,\n",
    "\n",
    "\n",
    "precision is given by\n",
    "\\begin{equation}\n",
    "precision = \\frac{TP}{TP + FP},\n",
    "\\end{equation}\n",
    "and recall is given by\n",
    "\\begin{equation}\n",
    "recall = \\frac{TP}{TP + FN}.\n",
    "\\end{equation}\n",
    "\n",
    "For an ideal system, there should exist a value of $\\tau$ such that\n",
    "both precision and recall are equal to $1$, which corresponds to\n",
    "obtaining all the correct images without any false matches. However, in\n",
    "reality both quantities will be somewhere in the range between $0$ and\n",
    "$1$ and the goal is to make both of them as high as possible.\n",
    "\n",
    "Implement a function `plot_rpc` in `utils/performance_evaluation.py` that you have to compute\n",
    "precision/recall pairs for a range of threshold values and then output\n",
    "the precision/recall curve (RPC), which gives a good summary of system\n",
    "performance at different levels of confidence. See **Figure 3** for an example of an RPC curve.\n",
    "\n",
    "**Q4.2** Plot RPC curves for different histogram types, distances, and number of bins. Submit a summary of your observations as part of your solution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 3: Recall/precision curve evaluated on the provided set of model and query images.**\n",
    "\n",
    "<!-- <img src=\"../../data/exercise-1/fig3.png\" width=\"400\" align=left /> -->\n",
    "![](../../data/exercise-1/fig3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.performance_evaluation import compare_dist_rpc\n",
    "\n",
    "# The following code is used for evaluation.\n",
    "\n",
    "with open('../../data/exercise-1/model.txt') as fp:\n",
    "    model_images = fp.readlines()\n",
    "model_images = [x.strip() for x in model_images] \n",
    "\n",
    "with open('../../data/exercise-1/query.txt') as fp:\n",
    "    query_images = fp.readlines()\n",
    "query_images = [x.strip() for x in query_images] \n",
    "\n",
    "eval_num_bins = 20\n",
    "\n",
    "plt.figure()\n",
    "compare_dist_rpc(model_images, query_images, ['chi2', 'intersect', 'l2'], 'rg', eval_num_bins, ['r', 'g', 'b'])\n",
    "plt.title('RG histograms')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "compare_dist_rpc(model_images, query_images, ['chi2', 'intersect', 'l2'], 'rgb', eval_num_bins, ['r', 'g', 'b'])\n",
    "plt.title('RGB histograms')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "compare_dist_rpc(model_images, query_images, ['chi2', 'intersect', 'l2'], 'dxdy', eval_num_bins, ['r', 'g', 'b'])\n",
    "plt.title('dx/dy histograms')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize your observations here: \n",
    "\n",
    "For all images, model with the **chi2** distance highest precision values however, it also yields lowest recall value. Therefore, for all images, model with the **chi2** is very selective (small number of true-positives) but yields most true cases.\n",
    "\n",
    "For *RG*, **intersect** and **l2** models yields similar precision and recall value although **intersect** model performs slightly better based on slightly higher recall and precision value.\n",
    "For *RGB*, **intersect** model yields high precision and high recall value compared to **l2** and **chi2**.\n",
    "For *dxdy*,**intersect** model performs slightly better in terms of high recall and high precision. However, after some point, precision-recall curves becomes siimilar with **l2** model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
